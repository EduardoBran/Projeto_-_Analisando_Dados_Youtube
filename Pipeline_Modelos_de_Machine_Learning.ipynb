{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee4ea025",
   "metadata": {},
   "source": [
    "# <span style=\"color: green; font-size: 40px; font-weight: bold;\"> Projeto  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844870b1",
   "metadata": {},
   "source": [
    "# Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865fc605",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Importando Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c16993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed4dcccb",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Carregando Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8479b6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c072de",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 34px; font-weight: bold;\"> Análise Exploratória de Dados </span>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Análise Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed763d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações do DataFrame\n",
    "print('\\n-------------------------------------------------------------------------------------------\\n\\n')\n",
    "print('INFO\\n\\n')\n",
    "dados.info()\n",
    "\n",
    "# Verifica se há valores ausentes e duplicados\n",
    "valores_ausentes = dados.isna().sum().sum() > 0\n",
    "valores_duplicados = dados.duplicated().sum() > 0\n",
    "\n",
    "# Nomes das variáveis com valores ausentes\n",
    "variaveis_ausentes = dados.columns[dados.isna().any()].tolist()\n",
    "\n",
    "# Número de linhas duplicadas\n",
    "num_linhas_duplicadas = dados.duplicated().sum()\n",
    "\n",
    "# Porcentagem de linhas duplicadas\n",
    "porcentagem_linhas_duplicadas = (num_linhas_duplicadas / len(dados)) * 100\n",
    "\n",
    "# Exibe o resultado\n",
    "if valores_ausentes:\n",
    "    print(\"\\n\\nExistem valores ausentes:\", valores_ausentes)\n",
    "    print(\"Variáveis com valores ausentes:\", variaveis_ausentes)\n",
    "else:\n",
    "    print(\"\\n\\nNenhuma variável possui valores ausentes.\")\n",
    "\n",
    "if valores_duplicados:\n",
    "    print(\"\\nExistem valores duplicados:\", valores_duplicados)\n",
    "    print(\"Número de Linhas Duplicadas:\", num_linhas_duplicadas)\n",
    "    print(\"Porcentagem de Linhas Duplicadas: {:.2f}%\\n\\n\".format(porcentagem_linhas_duplicadas))\n",
    "else:\n",
    "    print(\"\\nNenhuma variável possui valores duplicados.\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de3008f",
   "metadata": {},
   "source": [
    "### Resumo\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b4d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79d448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f9dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ccf9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d48c461",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Analisando os Dados\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Visualizando Variáveis Categóricas e Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234d805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo Variáveis Categóricas (filtrando)\n",
    "dados.dtypes[dados.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34228f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo Variáveis Numéricas (filtrando)\n",
    "dados.dtypes[dados.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c9bf49",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Analisando Variáveis Categóricas\n",
    "\n",
    "#### Resumo Estatístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe (informando que é para somente variáveis categóricas)\n",
    "print('\\nDescribe\\n')\n",
    "display(dados.describe(include = ['object']))\n",
    "print('\\n------------------------------------------------------------------------\\n\\n')\n",
    "\n",
    "# Verificando Tipo das Variáveis (adicionar mais variáveis se necessário)\n",
    "print('\\nTipo das Variáveis\\n')\n",
    "print(dados['genre'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os gráficos de contagem para todas as variáveis categóricas (adicionar variáveis categóricas necessárias)\n",
    "categorical_vars = ['genre']\n",
    "\n",
    "for var in categorical_vars:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=dados, x=var, label='Count')\n",
    "    plt.title(f'Contagem de {var}')\n",
    "    plt.xlabel(var.replace('_', ' ').capitalize())\n",
    "    plt.ylabel('Contagem')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Value counts para todas as variáveis categóricas\n",
    "for var in categorical_vars:\n",
    "    var_counts = dados[var].value_counts()\n",
    "    print(f\"\\nContagem de {var.replace('_', ' ').capitalize()}:\")\n",
    "    for category, count in var_counts.items():\n",
    "        print(f'{category}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a34503",
   "metadata": {},
   "source": [
    "### Resumo da Análise\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f3558d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f7d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5ecfd29",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Aplicando Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variáveis categóricas (adicionar variáveis categóricas necessárias)\n",
    "categorical_vars = ['genre']\n",
    "\n",
    "# Aplicando Label Encoding\n",
    "label_encoders = {}\n",
    "for var in categorical_vars:\n",
    "    le = LabelEncoder()\n",
    "    dados[var] = le.fit_transform(dados[var])\n",
    "    label_encoders[var] = le\n",
    "    \n",
    "# Verificando os tipos das variáveis\n",
    "print('\\nTipos das Variáveis Após Label Encoding\\n')\n",
    "print(dados.dtypes)\n",
    "\n",
    "# Verificando os valores únicos de 'income'\n",
    "print('\\n\\n-------------------------------------------------------------------------------------------------')\n",
    "print('\\nValores Únicos da Variável Alvo (genre)\\n')\n",
    "print(dados['genre'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af763322",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Analisando Todas as Variáveis\n",
    "\n",
    "#### Resumo Estatístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f49c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o formato original\n",
    "original_float_format = pd.options.display.float_format\n",
    "\n",
    "# Ajustar a exibição do pandas para valores sem notação científica\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Verificando o resumo estatístico sem notação científica\n",
    "print('\\nSem Notação Científica')\n",
    "display(dados.describe())\n",
    "print('\\n----------------------------------------------------------------------------------------------\\n\\n')\n",
    "\n",
    "# Restaurar o formato original\n",
    "pd.options.display.float_format = original_float_format\n",
    "\n",
    "# Verificando o resumo estatístico novamente para confirmar que voltou ao normal\n",
    "#print('\\nCom Notação Científica')\n",
    "#display(dados.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4136ffe",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Visualizando através de Gráficos Histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2554f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "dados.hist(figsize = (15,15), bins = 10) \n",
    "plt.show()\n",
    "\n",
    "print('\\n\\n------------------------------------------------------------------------------------------------\\n')\n",
    "\n",
    "# Visualização dos outliers\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=dados)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Boxplot para Detecção de Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc14754",
   "metadata": {},
   "source": [
    "### Resumo da Análise\n",
    "\n",
    "<table border=\"2\">\n",
    "  <tr>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Nome Da Varivel</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Resumo_Análise</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Tratamento Antes Divisão</th>\n",
    "    <th style=\"text-align: center; font-size: 16px;\">Tratamento Depois Divisão</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>energy</td>\n",
    "    <td>Distribuição assimétrica com muitos valores altos, concentrando-se entre 0.6 e 1.0.</td>\n",
    "    <td>Remoção de Outliers</td>\n",
    "    <td>Transformação para Normalização</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>speechiness</td>\n",
    "    <td>Distribuição assimétrica, com muitos valores baixos concentrando-se perto de 0.</td>\n",
    "    <td>Remoção de Outliers</td>\n",
    "    <td>Transformação para Normalização</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>genre</td>\n",
    "    <td>Variável Alvo. Distribuição categórica dos gêneros musicais, já codificada numericamente.</td>\n",
    "    <td>Não Necessita de Tratamento</td>\n",
    "    <td>Não Necessita de Tratamento</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437923fb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Limpeza nos Dados\n",
    "\n",
    "<br>\n",
    "\n",
    "### Tratando Valores Ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2971d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73165ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cbd9c0c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Tratando Valores Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359c1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aef4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b36865d",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Tratando Valores Outliers\n",
    "\n",
    "- **Variáveis que Precisarão de Tratamento**: escrever aqui\n",
    "\n",
    "<br>\n",
    "\n",
    "> **Sugestão**:\n",
    "É mais apropriado tratar cada variável **individualmente**, pois cada uma possui uma distribuição e comportamento diferente. Tratando-as individualmente, podemos aplicar métodos específicos para cada caso, o que resulta em uma limpeza mais precisa e adequada para o modelo.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Tipos de Tratamento de Outliers\n",
    "\n",
    "#### Isolation Forest\n",
    "\n",
    "- **Vantagens**: Lida com alta dimensionalidade, não assume distribuição dos dados.\n",
    "- **Desvantagens**: Sensível aos parâmetros, difícil de interpretar.\n",
    "\n",
    "#### Método IQR (Interquartile Range)\n",
    "\n",
    "- **Vantagens**: Simples de implementar e interpretar, eficaz para distribuições simétricas.\n",
    "- **Desvantagens**: Não adequado para distribuições assimétricas ou dados de alta dimensionalidade.\n",
    "\n",
    "#### Métodos Particulares\n",
    "\n",
    "- **Winsorização**: Limita valores outliers a um certo percentil.\n",
    "- **Remoção de Outliers**: Exclui completamente as observações outliers.\n",
    "- **Transformações**: Aplica transformações (log, sqrt, box-cox) para reduzir o impacto dos outliers.\n",
    "- **Substituição com Médias/Medianas**: Substitui outliers por valores médios ou medianos.\n",
    "\n",
    "#### Outros Métodos Avançados\n",
    "\n",
    "- **Clusterização (e.g., DBSCAN)**: Identifica outliers como pontos fora de clusters densos.\n",
    "- **Análise de Componentes Principais (PCA)**: Identifica outliers em um espaço de componentes principais reduzido.\n",
    "- **Modelos Baseados em Distribuições**: Modela a distribuição dos dados e identifica pontos com baixa probabilidade.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc92ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd854a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9fc0b63",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Features Engineering (se necessário)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ed960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206730a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25b90497",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Clusterização\n",
    "\n",
    "- A técnica de **clusterização cria uma nova variável** que representa os clusters identificados no conjunto de dados. Esta nova variável pode ser usada como uma feature adicional na criação de modelos preditivos, fornecendo informações sobre os padrões identificados durante a clusterização.\n",
    "- Verificar **variáveis relevantes** para a clusterização.\n",
    "- Verificar no gráfico de cotovelo \n",
    "\n",
    "<br>\n",
    "\n",
    "#### Preparação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb99a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparação dos Dados\n",
    "\n",
    "# Selecionar as variáveis relevantes para a clusterização (verificar veriáveis)\n",
    "variables = ['']\n",
    "\n",
    "# Criar um DataFrame apenas com as variáveis selecionadas\n",
    "cluster_data = dados[variables]\n",
    "\n",
    "# Normalizar os dados\n",
    "scaler = StandardScaler()\n",
    "cluster_data_scaled = scaler.fit_transform(cluster_data)\n",
    "\n",
    "\n",
    "## Escolha do Algoritmo de Clusterização e Avaliação do Número Ótimo de Clusters\n",
    "\n",
    "# Avaliar o método do cotovelo para encontrar o número ótimo de clusters\n",
    "sse = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(cluster_data_scaled)\n",
    "    sse.append(kmeans.inertia_)\n",
    "\n",
    "# Plotar o gráfico do método do cotovelo\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 11), sse, marker='o')\n",
    "plt.title('Método do Cotovelo')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa09ad49",
   "metadata": {},
   "source": [
    "#### Execução da Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a2b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execução da Clusterização e Criação da Nova Variável\n",
    "\n",
    "# Escolher o número de clusters com base no gráfico do método do cotovelo (onde a cauda começa a abaixar)\n",
    "optimal_clusters = 4\n",
    "\n",
    "# Aplicar K-Means com o número ótimo de clusters\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "dados['Cluster'] = kmeans.fit_predict(cluster_data_scaled)\n",
    "\n",
    "# Verificar as novas colunas criadas\n",
    "print(\"\\nNovas colunas criadas:\")\n",
    "print(dados.columns)\n",
    "\n",
    "# Exibir uma amostra do DataFrame para verificar as novas colunas\n",
    "display(dados.head(10))\n",
    "\n",
    "# Visualizar os clusters resultantes\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.scatterplot(x='Total_Damages', y='Total_Affected', hue='Cluster', data=dados, palette='viridis')\n",
    "plt.title('Clusterização de Regiões e Tipos de Desastres')\n",
    "plt.xlabel('Total de Danos')\n",
    "plt.ylabel('Total de Afetados')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Mostrar a contagem de observações em cada cluster\n",
    "print(dados['Cluster'].value_counts())\n",
    "\n",
    "# Analisar as características médias de cada cluster\n",
    "cluster_summary = dados.groupby('Cluster')[variables].mean()\n",
    "display(cluster_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190f6b22",
   "metadata": {},
   "source": [
    "#### Verificando Desempenho da Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1694e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calcular a pontuação de silhueta\n",
    "silhouette_avg = silhouette_score(cluster_data_scaled, dados['Cluster'])\n",
    "print(f'Pontuação de Silhueta: {silhouette_avg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575e5ee",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Verificando Correlação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c456a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Verificando Correlações através de Tabela\n",
    "\n",
    "# Criando Tabela\n",
    "display(dados.corr())\n",
    "\n",
    "print('\\n\\n=================================================================================================\\n')\n",
    "\n",
    "\n",
    "## Visualizando Correlações através de um Mapa de Calor\n",
    "\n",
    "# Criando o Heatmap\n",
    "corr_matrix = dados.select_dtypes(include=[np.number]).corr()\n",
    "\n",
    "plt.figure(figsize=(16, 12))  # Define o tamanho da figura maior\n",
    "heatmap = sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1, cbar=True, square=True, annot_kws={\"size\": 10})\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), rotation=45, horizontalalignment='right', fontsize=12)  # Aumenta a fonte das labels\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), rotation=0, fontsize=12)  # Aumenta a fonte das labels\n",
    "plt.title('Mapa de Calor das Correlações', fontsize=18)  # Aumenta o título\n",
    "plt.tight_layout()  # Ajusta o layout para evitar corte de labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e182366",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Resumo da Análise:\n",
    "\n",
    "#### Análise das Principais Correlações com a Variável Alvo\n",
    "\n",
    "- \n",
    "\n",
    "#### Variáveis a serem removidas:\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedc48c",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# Seleção de Variáveis Usando RandomForest\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005d8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93725edd",
   "metadata": {},
   "source": [
    "### Conclusão\n",
    "\n",
    "- Combinando a **análise de correlação** e a **análise de importância das variáveis**, a recomendação é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4199d724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3afb56ad",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# Pré-Processamento de Dados Para Construção de Modelos de Machine Learning\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "## Dividindo os dados em Dados de Treino e Dados de Teste\n",
    "- Nós **treinamos** o modelo com **dados de treino** e **avaliamos** o modelo com **dados de teste**.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305aee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um objeto separado para a variável alvo\n",
    "y = dados.income\n",
    "\n",
    "# Cria um objeto separado para as variáveis de entrada\n",
    "X = dados.drop('income', axis=1)\n",
    "\n",
    "# Split em dados de treino e teste sem amostragem estratificada\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=1234)\n",
    "\n",
    "# Print do shape\n",
    "print(X_treino.shape, X_teste.shape, y_treino.shape, y_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eefbbe",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajusta e transforma os dados de treino\n",
    "X_treino_scaled = scaler.fit_transform(X_treino)\n",
    "\n",
    "# Apenas transforma os dados de teste\n",
    "X_teste_scaled = scaler.transform(X_teste)\n",
    "\n",
    "# Verifica os shapes dos dados escalados\n",
    "print(X_treino_scaled.shape, X_teste_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81867ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Despadronizar\n",
    "\n",
    "#import joblib\n",
    "\n",
    "# Salva o objeto scaler ajustado\n",
    "#joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Carrega o scaler ajustado\n",
    "#scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Despadroniza os dados\n",
    "#X_treino_original = scaler.inverse_transform(X_treino_scaled)\n",
    "#X_teste_original = scaler.inverse_transform(X_teste_scaled)\n",
    "\n",
    "# Verifica os shapes dos dados despadronizados\n",
    "#print(X_treino_original.shape, X_teste_original.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a939bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48b96cfa",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "<span style=\"color: green; font-size: 40px; font-weight: bold;\">Construindo Modelos de Machine Learning</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Nesta etapa do projeto o ideal é escolher um algoritmo simples e fácil de compreender, que será usado como Benchmark (modelo base).\n",
    "\n",
    "#### Importante\n",
    "\n",
    "- Iremos treinar dois conjuntos de dados: um **conjunto de dados com todas as variáveis** e outro **variáveis selecionadas**.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "## Criando Dataframe para salvar métricas de cada Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688031e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um dataframe para receber as métricas de cada modelo\n",
    "df_modelos = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49d79c",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-weight: bold;\">Modelo 1 com Regressão Logística (Benchmark)</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "> # Versão 1\n",
    "\n",
    "- Sem Ajuste de Hiperparâmetros\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### Criação, Treinamento, Previsão e Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4faee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03066409",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Salvando as Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70be005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DataFrame para salvar as métricas\n",
    "modelo_v1 = pd.DataFrame({\n",
    "    'Nome do Modelo': ['Logistic Regression\t'],\n",
    "    'Versao': ['1'],\n",
    "    'Tipo de Dados': ['Todas as Variáveis'],\n",
    "    'Tipo de Modelo': ['Sem Ajuste de Hiperparâmetros'],\n",
    "    'MAE': [f\"{mae:.2f}\"],\n",
    "    'MSE': [f\"{mse:.2f}\"],\n",
    "    'RMSE': [rmse],\n",
    "    'Coeficiente R2': [r2],\n",
    "    'Variância Explicada': [evs]\n",
    "})\n",
    "\n",
    "# Concatenando com o DataFrame existente\n",
    "df_modelos = pd.concat([df_modelos, modelo_v1], ignore_index=True)\n",
    "\n",
    "# Visualizando DataFrame\n",
    "display(df_modelos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80626863",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "> # Versão 2\n",
    "\n",
    "- Com Ajuste de Hiperparâmetros\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "### Configurando Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b770dddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5848f10",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Criação, Treinamento, Previsão e Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf13f9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3338c852",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Salvando as Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9801b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed20321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167eb3fd-97f9-4b05-8fcf-90004a30223e",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "# SELECIONANDO O MELHOR MODELO\n",
    "\n",
    "- Usaremos o modelo que .\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Visualizando Dataframe Ordenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc7dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenando o DataFrame pelo (modificar sort_values)\n",
    "df_modelos_sorted = df_modelos.sort_values(by='AUC Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Visualizando Daframe\n",
    "display(df_modelos_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff553dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "632f8a4d",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "## Salvando e Carregando Melhor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366b780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d0e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f7aecf5",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "# <span style=\"color: green; font-size: 38px; font-weight: bold;\">CRIANDO INTERFACE</span>\n",
    "\n",
    "<br>\n",
    "\n",
    "# Versão 1\n",
    "\n",
    "- Usando **Jupyter Widgets**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442345cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90173baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d3ba470",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "\n",
    "====================================================================================================================\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# Versão 2\n",
    "\n",
    "- Versão mais elaborada usando o **Streamlit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff99aa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a664a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b4627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a7ad6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1678944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c0f4f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd0611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cfc96d9",
   "metadata": {},
   "source": [
    "<table border=\"2\" style=\"font-size: 14px; border-spacing: 10px;\">\n",
    "  <caption style=\"font-size: 32px; margin: 30px; text-align: center\">Pipeline para Modelos de Machine Learning (ML)</caption>\n",
    "  <tr>\n",
    "    <th style=\"text-align: center; font-size: 20px;\">Passo</th>\n",
    "    <th style=\"text-align: center; font-size: 20px;\">Descrição</th>\n",
    "    <th style=\"text-align: center; font-size: 20px;\">Comentário</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Definir Objetivo e Pergunta de Negócio</td>\n",
    "    <td>Determinar o objetivo do projeto e as principais perguntas de negócio a serem respondidas.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>2</td>\n",
    "    <td>Importar Pacotes</td>\n",
    "    <td>Importar as bibliotecas e pacotes necessários para o projeto.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>3</td>\n",
    "    <td>Carregar dados</td>\n",
    "    <td>Esta é a primeira etapa essencial para qualquer projeto de Data Science.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>4</td>\n",
    "    <td>Analisar Dados de forma Geral</td>\n",
    "    <td>Análise exploratória inicial para entender a estrutura e o conteúdo dos dados.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>5</td>\n",
    "    <td>Remoção de Variáveis Completamente Irrelevantes</td>\n",
    "    <td>Remover variáveis que não contribuem para a análise ou que são completamente irrelevantes.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>6</td>\n",
    "    <td>Renomear variáveis (se necessário)</td>\n",
    "    <td>Renomear as variáveis para melhor visualização e entendimento dos dados.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>7</td>\n",
    "    <td>Analisar Dados de Variáveis Categóricas</td>\n",
    "    <td>É importante entender a distribuição e as características das variáveis categóricas.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>8</td>\n",
    "    <td>Aplicar se necessário algum tratamento nas variáveis categóricas antes do Label Encode</td>\n",
    "    <td>Tratamentos como combinação de categorias raras ou correção de inconsistências devem ser feitos antes da codificação.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>9</td>\n",
    "    <td>Aplicar Label Encode nas variáveis categóricas</td>\n",
    "    <td>Convertendo variáveis categóricas em numéricas.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>10</td>\n",
    "    <td>Analisar Todas as Variáveis com describe e gráficos</td>\n",
    "    <td>Análise estatística e visual de todas as variáveis para identificar padrões e anomalias.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>11</td>\n",
    "    <td>Aplicar tratamento de Valores Ausentes</td>\n",
    "    <td>Tratar valores ausentes antes da modelagem para evitar problemas.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>12</td>\n",
    "    <td>Aplicar Tratamento para Linhas Duplicadas</td>\n",
    "    <td>Remover ou lidar com linhas duplicadas para garantir a qualidade dos dados.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>13</td>\n",
    "    <td>Aplicar Tratamento para Valores Outliers</td>\n",
    "    <td>Identificar e tratar outliers que possam afetar a performance do modelo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>14</td>\n",
    "    <td>Features Engineering (se necessário)</td>\n",
    "    <td>Criar novas variáveis ou transformar variáveis existentes para melhorar a capacidade preditiva do modelo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>15</td>\n",
    "    <td>Aplicar Clusterização (se necessário)</td>\n",
    "    <td>Identificar padrões ou segmentos nos dados para insights adicionais.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>16</td>\n",
    "    <td>Análise de Correlação</td>\n",
    "    <td>Identificar relações entre as variáveis que podem informar a seleção de variáveis.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>17</td>\n",
    "    <td>Seleção de Variáveis</td>\n",
    "    <td>Selecionar as variáveis mais relevantes para a modelagem.</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>18</td>\n",
    "    <td>Remoção de Variáveis Após Análise de Correlação e Seleção de Variáveis (se necessário)</td>\n",
    "    <td>Remover variáveis que não são relevantes com base nas análises de correlação e Seleção de Variáveis.</td>\n",
    "  </tr>  \n",
    "  <tr>\n",
    "    <td>19</td>\n",
    "    <td>Divisão dos Dados em Treino e Teste</td>\n",
    "    <td>Separar os dados para validar o desempenho do modelo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>20</td>\n",
    "    <td>Aplicar Normalização ou Padronização (Depende dos dados)</td>\n",
    "    <td>Aplicar transformações de escala. Normalizar ou padronizar os dados após a divisão em treino e teste para evitar vazamento de dados.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>21</td>\n",
    "    <td>Criar Modelo Benchmark para ver como está o desempenho do modelo inicial</td>\n",
    "    <td>Criar um modelo inicial simples para ter uma linha de base de desempenho.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>22</td>\n",
    "    <td>Se o modelo Benchmark estiver muito ruim, estudar formas de tentar melhorar o conjunto de dados</td>\n",
    "    <td>Melhorar os dados, se necessário, para tentar aumentar o desempenho do modelo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>23</td>\n",
    "    <td>Treinar outros algoritmos</td>\n",
    "    <td>Testar múltiplos algoritmos para encontrar o mais adequado.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>24</td>\n",
    "    <td>Verificar desempenho dos algoritmos</td>\n",
    "    <td>Comparar os desempenhos para selecionar o melhor modelo.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>25</td>\n",
    "    <td>Escolher e salvar o melhor modelo</td>\n",
    "    <td>Selecionar o modelo com melhor desempenho e salvá-lo para uso futuro, incluindo no pipeline as informações necessárias para desnormalizar ou despadronizar os dados, bem como os labels e outras configurações.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>26</td>\n",
    "    <td>Testar o modelo com dados novos</td>\n",
    "    <td>Validar o modelo com novos dados para verificar sua capacidade de generalização.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>27</td>\n",
    "    <td>Criar uma Interface Gráfica do Modelo</td>\n",
    "    <td>Criar uma interface gráfica pode ser útil, mas não é um passo essencial em todos os projetos de Data Science.</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0791e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Padronização x Normalização\n",
    "\n",
    "As técnicas de padronização e normalização são usadas no pré-processamento de dados em aprendizado de máquina para preparar variáveis numéricas, ajustando suas escalas. Aqui está quando e por que usar cada uma:\n",
    "\n",
    "<br>\n",
    "\n",
    "### Padronização\n",
    "Transforma os dados de modo que eles tenham média zero e desvio padrão igual a um. \n",
    "- **Quando usar**: Aplicável quando os dados já estão centralizados em torno de uma média e precisam de ajuste na escala. É útil em modelos como SVM e Regressão Logística, que são sensíveis a variações na escala das variáveis de entrada.\n",
    "- **Exemplo prático**: Se medimos altura em centímetros (150-190 cm) e peso em quilogramas (50-100 kg), a padronização permite comparar essas medidas numa escala comum, evitando distorções devido a diferentes intervalos de valores.\n",
    "- **Por que escolher para este projeto**: Optamos pela padronização porque as variáveis têm escalas muito diferentes e há a presença de outliers significativos. A padronização mantém as propriedades estatísticas dos dados, minimizando o impacto dos outliers, ao contrário da normalização que pode distorcer os dados ao comprimir a maioria dos valores em um intervalo estreito.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Normalização\n",
    "Ajusta os dados para que seus valores caibam em um intervalo predefinido, geralmente de **0 a 1**.\n",
    "- **Quando usar**: Ideal para dados com variações extremas nas escalas e onde os algoritmos são sensíveis à magnitude absoluta dos dados, como K-Nearest Neighbors (KNN) e técnicas de clustering.\n",
    "- **Exemplo prático**: Se um dataset contém preços de produtos variando de R$1 a R$1000 e quantidades vendidas de 1 a 20 unidades, a normalização faria com que ambos os atributos tivessem a mesma contribuição no modelo, independentemente da escala original.\n",
    "- **Por que não usamos aqui**: Não foi escolhida devido à presença de outliers, que poderiam ser enfatizados indevidamente, e porque a normalização poderia limitar a eficácia de modelos que assumem uma distribuição normal dos dados.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Importante:\n",
    "- **Não é necessário** aplicar padronização/normalização na **variável alvo**.\n",
    "- Nós **não aplicamos** as duas técnicas, ou usamos uma ou outra.\n",
    "- A **normalização** pode não ser a melhor escolha se houver **outliers significativos no conjunto de dados**, pois isso poderia comprimir a maioria dos dados em um intervalo muito estreito. Nesses casos, a **padronização é recomendada**.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5510a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
